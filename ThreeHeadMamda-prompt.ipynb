{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from utils.loss_function import SaliencyLoss\n",
    "from utils.data_process_uni import TrainDataset,ValDataset\n",
    "from net.models.SUM import SUM\n",
    "from net.configs.config_setting import setting_config\n",
    "import sys\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the dataframe\n",
    "df = pd.read_csv('HandInfo.csv')\n",
    "age_bins = [0, 21, 22, 23, 24, 31, 76]\n",
    "labels = np.arange(6)\n",
    "df['age_category'] = pd.cut(df['age'], bins=age_bins, labels=labels, right=False, include_lowest=True)\n",
    "df = df[df.accessories == 0]\n",
    "df['p'] = np.where(df.aspectOfHand.str.startswith('p') == True, 1, 0)\n",
    "df['r'] = np.where(df.aspectOfHand.str.endswith('right') == True, 1, 0)\n",
    "df_p_r = df[(df.p == 1) & (df.r == 1)]\n",
    "df_p_l = df[(df.p == 1) & (df.r == 0)]\n",
    "df_d_r = df[(df.p == 0) & (df.r == 1)]\n",
    "df_d_l = df[(df.p == 0) & (df.r == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_directory = 'Hands'\n",
    "batch_size = 16\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "lr = 1e-5\n",
    "split_size = 0.2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = setting_config\n",
    "model_cfg = config.model_config\n",
    "# Training and Validation Loop\n",
    "best_loss = float('inf')\n",
    "num_epochs = 80\n",
    "# Early stopping setup\n",
    "early_stop_counter = 0\n",
    "early_stop_threshold = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the data augmentation and normalization transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)], p=0.5),\n",
    "        transforms.Resize((img_height, img_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "def split_data(df, test_size=split_size):\n",
    "    train_df, val_df = train_test_split(df, test_size=test_size, stratify=df['id'], random_state=42)\n",
    "    return train_df, val_df\n",
    "\n",
    "def encode(col, encoder, val_df, train_df):\n",
    "    encoder.fit(train_df[col])\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    val_df[col] = encoder.transform(val_df[col])\n",
    "\n",
    "train_df_p_r, val_df_p_r = split_data(df_p_r)\n",
    "train_df_p_l, val_df_p_l = split_data(df_p_l)\n",
    "train_df_d_r, val_df_d_r = split_data(df_d_r)\n",
    "train_df_d_l, val_df_d_l = split_data(df_d_l)\n",
    "\n",
    "train_df = pd.concat([train_df_p_r, train_df_d_r, train_df_p_l, train_df_d_l])\n",
    "val_df = pd.concat([val_df_p_r, val_df_d_r, val_df_p_l, val_df_d_l])\n",
    "data_len = train_df.shape[0]\n",
    "\n",
    "pairs = [('id', LabelEncoder()), ('age_category', LabelEncoder()), ('gender', LabelEncoder())]\n",
    "for pair in pairs:\n",
    "    encode(pair[0], pair[1], val_df, train_df)\n",
    "train_id_one_hot = pd.get_dummies(train_df['id'])\n",
    "val_id_one_hot = pd.get_dummies(val_df['id'])\n",
    "train_age_one_hot = pd.get_dummies(train_df['age_category'])\n",
    "val_age_one_hot = pd.get_dummies(val_df['age_category'])\n",
    "train_gender_one_hot = pd.get_dummies(train_df['gender'])\n",
    "val_gender_one_hot = pd.get_dummies(val_df['gender'])\n",
    "num_classes1 = len(pairs[0][1].classes_)\n",
    "num_classes2 = len(pairs[1][1].classes_)\n",
    "num_classes3 = len(pairs[2][1].classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HandDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.labels1, self.labels2, self.labels3 = labels\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx]['imageName'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label1 = self.labels1.iloc[idx].values.astype(float)\n",
    "        label2 = self.labels2.iloc[idx].values.astype(float)\n",
    "        label3 = self.labels3.iloc[idx].values.astype(float)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, [torch.tensor(label1), torch.tensor(label2), torch.tensor(label3)]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HandDataset(train_df, [train_id_one_hot, train_age_one_hot, train_gender_one_hot], image_directory, transform=data_transforms['train'])\n",
    "val_dataset = HandDataset(val_df, [val_id_one_hot, val_age_one_hot, val_gender_one_hot], image_directory, transform=data_transforms['val'])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##---------- Prompt Gen Module -----------------------\n",
    "class PromptGenBlock(nn.Module):\n",
    "    def __init__(self, prompt_dim=128, prompt_len=5, prompt_size=96, lin_dim=192):\n",
    "        super(PromptGenBlock, self).__init__()\n",
    "        self.prompt_param = nn.Parameter(torch.rand(1, prompt_len, prompt_dim, prompt_size, prompt_size))\n",
    "        self.linear_layer = nn.Linear(lin_dim, prompt_len)\n",
    "        self.conv3x3 = nn.Conv2d(prompt_dim, prompt_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        emb = x.mean(dim=(-2, -1))\n",
    "        prompt_weights = F.softmax(self.linear_layer(emb), dim=1)\n",
    "        prompt = prompt_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1) * self.prompt_param.unsqueeze(0).repeat(B, 1,\n",
    "                                                                                                                  1, 1,\n",
    "                                                                                                                  1,\n",
    "                                                                                                                  1).squeeze(\n",
    "            1)\n",
    "        prompt = torch.sum(prompt, dim=1)\n",
    "        prompt = F.interpolate(prompt, (H, W), mode=\"bilinear\")\n",
    "        prompt = self.conv3x3(prompt)\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, sum_model, num_classes1, num_classes2, num_classes3, input_features, dropout_rate=0.5):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.sum_model = sum_model\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Prompt blocks for each head\n",
    "        self.prompt_block1 = PromptGenBlock(prompt_dim=768, prompt_len=5, prompt_size=8, lin_dim=768)\n",
    "        self.prompt_block2 = PromptGenBlock(prompt_dim=768, prompt_len=5, prompt_size=8, lin_dim=768)\n",
    "        self.prompt_block3 = PromptGenBlock(prompt_dim=768, prompt_len=5, prompt_size=8, lin_dim=768)\n",
    "        self.adjust_conv_layer = nn.Conv2d(768 * 2, 768, kernel_size=1)\n",
    "        \n",
    "        # first fully connected layers\n",
    "        self.fc1_1 = nn.Linear(input_features, 512)\n",
    "        self.bn1_1 = nn.BatchNorm1d(512)\n",
    "        self.fc2_1 = nn.Linear(512, 256)\n",
    "        self.bn2_1 = nn.BatchNorm1d(256)\n",
    "        self.fc3_1 = nn.Linear(256, num_classes1)\n",
    "        # second fully connected layers\n",
    "        self.fc1_2 = nn.Linear(input_features, 256)\n",
    "        self.bn1_2 = nn.BatchNorm1d(256)\n",
    "        self.fc2_2 = nn.Linear(256, 128)\n",
    "        self.bn2_2 = nn.BatchNorm1d(128)\n",
    "        self.fc3_2 = nn.Linear(128, num_classes2)\n",
    "        # third fully connected layers\n",
    "        self.fc1_3 = nn.Linear(input_features, 128)\n",
    "        self.bn1_3 = nn.BatchNorm1d(128)\n",
    "        self.fc2_3 = nn.Linear(128, 64)\n",
    "        self.bn2_3 = nn.BatchNorm1d(64)\n",
    "        self.fc3_3 = nn.Linear(64, num_classes3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sum_model(x) # torch.Size([B, 7, 7, 768])\n",
    "        \n",
    "        ### APPLY Prompt for first head\n",
    "        prompt_input1 = x.permute(0, 3, 1, 2)  # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output1 = self.prompt_block1(prompt_input1) # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output1 = torch.cat([prompt_input1, prompt_output1], dim=1) # torch.Size([B, 1536, 7, 7])\n",
    "        prompt_output1 = self.adjust_conv_layer(prompt_output1) # torch.Size([B, 768, 7, 7])\n",
    "        x1 = prompt_output1.permute(0, 2, 3, 1) # torch.Size([B, 7, 7, 768])\n",
    "        x1 = self.flatten(x1)\n",
    "        \n",
    "        ### APPLY Prompt for second head\n",
    "        prompt_input2 = x.permute(0, 3, 1, 2)  # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output2 = self.prompt_block2(prompt_input2) # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output2 = torch.cat([prompt_input2, prompt_output2], dim=1) # torch.Size([B, 1536, 7, 7])\n",
    "        prompt_output2 = self.adjust_conv_layer(prompt_output2) # torch.Size([B, 768, 7, 7])\n",
    "        x2 = prompt_output2.permute(0, 2, 3, 1) # torch.Size([B, 7, 7, 768])\n",
    "        x2 = self.flatten(x2)\n",
    "        \n",
    "        ### APPLY Prompt for third head\n",
    "        prompt_input3 = x.permute(0, 3, 1, 2)  # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output3 = self.prompt_block3(prompt_input3) # torch.Size([B ,768, 7, 7])\n",
    "        prompt_output3 = torch.cat([prompt_input3, prompt_output3], dim=1) # torch.Size([B, 1536, 7, 7])\n",
    "        prompt_output3 = self.adjust_conv_layer(prompt_output3) # torch.Size([B, 768, 7, 7])\n",
    "        x3 = prompt_output3.permute(0, 2, 3, 1) # torch.Size([B, 7, 7, 768])\n",
    "        x3 = self.flatten(x3)\n",
    "        \n",
    "        # Forward through the first separate fully connected network\n",
    "        out1 = torch.relu(self.bn1_1(self.fc1_1(x1)))\n",
    "        out1 = self.dropout(out1)\n",
    "        out1 = torch.relu(self.bn2_1(self.fc2_1(out1)))\n",
    "        out1 = self.dropout(out1)\n",
    "        out1 = self.fc3_1(out1)\n",
    "        \n",
    "        # Forward through the second separate fully connected network\n",
    "        out2 = torch.relu(self.bn1_2(self.fc1_2(x2)))\n",
    "        out2 = self.dropout(out2)\n",
    "        out2 = torch.relu(self.bn2_2(self.fc2_2(out2)))\n",
    "        out2 = self.dropout(out2)\n",
    "        out2 = self.fc3_2(out2)\n",
    "        \n",
    "        # Forward through the third separate fully connected network\n",
    "        out3 = torch.relu(self.bn1_3(self.fc1_3(x3)))\n",
    "        out3 = self.dropout(out3)\n",
    "        out3 = torch.relu(self.bn2_3(self.fc2_3(out3)))\n",
    "        out3 = self.dropout(out3)\n",
    "        out3 = self.fc3_3(out3)\n",
    "        \n",
    "        return out1, out2, out3\n",
    "    \n",
    "    # Assuming the SUM class is already defined as per your model\n",
    "if config.network == 'sum':\n",
    "    sum_model = SUM(\n",
    "        num_classes=model_cfg['num_classes'],\n",
    "        input_channels=model_cfg['input_channels'],\n",
    "        depths=model_cfg['depths'],\n",
    "        depths_decoder=model_cfg['depths_decoder'],\n",
    "        drop_path_rate=model_cfg['drop_path_rate'],\n",
    "        load_ckpt_path=model_cfg['load_ckpt_path'],\n",
    "    )\n",
    "    sum_model.load_from()\n",
    "    sum_model.cuda()\n",
    "\n",
    "    \n",
    "input_features = 7 * 7 * 768  # Adjust this value based on your model's output shape\n",
    "model = FullyConnectedNetwork(sum_model, num_classes1, num_classes2, num_classes3, input_features)\n",
    "model.cuda()    \n",
    "\n",
    "# Set up criterion, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Use CrossEntropyLoss with label smoothing\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter('runs/experiment_prompt2')\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, patience=10, base_model_path=\"model_prompt.pth\"):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            #     data_loader = val_loader\n",
    "\n",
    "            # running_loss = 0.0\n",
    "            # running_corrects1 = 0\n",
    "            # running_corrects2 = 0\n",
    "            # running_corrects3 = 0\n",
    "\n",
    "            # # Iterate over data\n",
    "            # for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "            #     inputs = inputs.to(device)\n",
    "            #     labels1, labels2, labels3 = labels\n",
    "            #     labels1 = labels1.to(device)\n",
    "            #     labels2 = labels2.to(device)\n",
    "            #     labels3 = labels3.to(device)\n",
    "\n",
    "            #     # Zero the parameter gradients\n",
    "            #     optimizer.zero_grad()\n",
    "\n",
    "            #     # Forward\n",
    "            #     with torch.set_grad_enabled(phase == 'train'):\n",
    "            #         outputs1, outputs2, outputs3 = model(inputs)\n",
    "            #         _, preds1 = torch.max(outputs1, 1)\n",
    "            #         _, preds2 = torch.max(outputs2, 1)\n",
    "            #         _, preds3 = torch.max(outputs3, 1)\n",
    "            #         loss1 = criterion(outputs1, labels1.argmax(dim=1))\n",
    "            #         loss2 = criterion(outputs2, labels2.argmax(dim=1))\n",
    "            #         loss3 = criterion(outputs3, labels3.argmax(dim=1))\n",
    "            #         loss = loss1 + loss2 + loss3\n",
    "\n",
    "            #         # Backward + optimize only if in training phase\n",
    "            #         if phase == 'train':\n",
    "            #             loss.backward()\n",
    "            #             optimizer.step()\n",
    "\n",
    "            #     # Statistics\n",
    "            #     running_loss += loss.item() * inputs.size(0)\n",
    "            #     running_corrects1 += torch.sum(preds1 == labels1.argmax(dim=1).data)\n",
    "            #     running_corrects2 += torch.sum(preds2 == labels2.argmax(dim=1).data)\n",
    "            #     running_corrects3 += torch.sum(preds3 == labels3.argmax(dim=1).data)\n",
    "\n",
    "            #     # Print loss status after each batch\n",
    "            #     if phase == 'train':\n",
    "            #         sys.stdout.write(f'\\rBatch {batch_idx}/{len(data_loader) - 1} Loss: {loss.item():.4f}')\n",
    "            #         sys.stdout.flush()\n",
    "\n",
    "            # epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            # epoch_acc1 = running_corrects1.double() / len(data_loader.dataset)\n",
    "            # epoch_acc2 = running_corrects2.double() / len(data_loader.dataset)\n",
    "            # epoch_acc3 = running_corrects3.double() / len(data_loader.dataset)\n",
    "\n",
    "            # # Log to TensorBoard\n",
    "            # writer.add_scalar(f'{phase}/Loss', epoch_loss, epoch)\n",
    "            # writer.add_scalar(f'{phase}/Accuracy1', epoch_acc1, epoch)\n",
    "            # writer.add_scalar(f'{phase}/Accuracy2', epoch_acc2, epoch)\n",
    "            # writer.add_scalar(f'{phase}/Accuracy3', epoch_acc3, epoch)\n",
    "\n",
    "            # print(f'{phase} Loss: {epoch_loss:.4f} Acc1: {epoch_acc1:.4f} Acc2: {epoch_acc2:.4f} Acc3: {epoch_acc3:.4f}')\n",
    "\n",
    "    #         # Deep copy the model\n",
    "    #         if phase == 'val':\n",
    "    #             scheduler.step(epoch_loss)\n",
    "    #             avg_acc = (epoch_acc1 + epoch_acc2 + epoch_acc3) / 3\n",
    "    #             if avg_acc > best_acc:\n",
    "    #                 best_acc = avg_acc\n",
    "    #                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #                 epochs_no_improve = 0\n",
    "    #                 torch.save(model.state_dict(), base_model_path)  # Save the base model\n",
    "    #                 print(f\"Best model save at epoch {epoch}\")\n",
    "    #             else:\n",
    "    #                 epochs_no_improve += 1\n",
    "\n",
    "    #             if epochs_no_improve >= patience:\n",
    "    #                 print(f'Early stopping at epoch {epoch}')\n",
    "    #                 model.load_state_dict(best_model_wts)\n",
    "    #                 writer.close()\n",
    "    #                 return model\n",
    "\n",
    "    #     print()\n",
    "\n",
    "    # print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # # Load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    # writer.close()\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Train the model\n",
    "#model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=num_epochs, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./net/pre_trained_weights/model_prompt.pth\", map_location=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
